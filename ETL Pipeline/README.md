# ETL Pipeline Project for Shopping Dataset

## Project Description

This project is an ETL pipeline designed to process a shopping dataset. The pipeline includes data transformation, division into fact and dimension tables, and the loading of data into a PostgreSQL database.

### Key Steps:
- **Data Transformation**: Split the dataset into fact and dimension tables.
- **ETL Pipeline**: Implemented the ETL process with data cleaning, transformation, and loading to a PostgreSQL database.
- **PostgreSQL Integration**: Data is loaded into a PostgreSQL database for analytics.

## Getting Started

### Prerequisites

- Python 3.x
- PostgreSQL
- Required Python libraries (listed in `requirements.txt`)

### Setup Instructions

1. Clone the repository:
   ```bash
   git clone git clone https://github.com/SajaTaweel/MLOps.git
   
2. Navigate to the project folder:
    ```bash
   cd MLOps/ETL\ Pipeline

3. Install dependencies:
    ```bash
    pip install -r requirements.txt

4. Set up PostgreSQL with a database called shopping_data.

5. Run the pipeline:
    ```bash
    python src/etl/main.py
 





   



